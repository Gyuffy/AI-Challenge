{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99790,"databundleVersionId":12088017,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b08ef713-2de6-4e9c-a306-6586a374d77a","cell_type":"markdown","source":"## 1. 라이브러리 설치 및 불러오기  \nYOLO 모델을 실행하기 위한 환경을 구성하는 코드입니다.  \n필요한 패키지를 설치하고, 이미지 처리 및 데이터 로딩에 필요한 라이브러리를 불러옵니다.\n\n> ✅ 설치 패키지\n- `ultralytics`: YOLO 모델 실행 및 학습\n- `opencv-python`: 이미지 로딩 및 전처리\n- `numpy`, `matplotlib`: 데이터 처리 및 시각화\n\n> ✅ 불러오는 핵심 라이브러리\n- `torch`, `torchvision`: 모델 학습 및 데이터 전처리\n- `ultralytics.YOLO`: YOLO 모델 로딩\n- `cv2`, `numpy`: 이미지 처리 및 수치 계산\n- `tqdm`, `matplotlib.pyplot`: 시각화 및 진행 표시","metadata":{}},{"id":"e35203ed-0460-416e-af19-1afda7596d24","cell_type":"code","source":"!pip install ultralytics opencv-python numpy matplotlib tqdm pyyaml -q\n\nimport os\nimport cv2\nimport torch\nimport yaml\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom glob import glob\nfrom ultralytics import YOLO\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms","metadata":{},"outputs":[],"execution_count":null},{"id":"d116de0e-b972-4e9e-a0b6-b27180ccd59a","cell_type":"markdown","source":"## 2. 랜덤 시드 고정\n\n실험의 일관성을 유지하기 위해 `random`, `numpy`, `torch`의 시드를 고정합니다.  ","metadata":{}},{"id":"9e093257-b099-4663-834d-3e2191e2690b","cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\nseed_everything()","metadata":{},"outputs":[],"execution_count":null},{"id":"259a704a-027e-4dc8-8da9-1fd0eaf27f41","cell_type":"markdown","source":"## 3. 데이터 경로 설정 및 YAML 파일 로드\n`data.yaml` 파일을 불러와 학습(train), 검증(val) 데이터의 경로를 설정합니다.\n\n> ✅ 학습 데이터는 모델을 학습시키는 데 사용되며,  \n> ✅ 검증 데이터는 학습 중 모델의 성능을 평가하고 과적합 여부를 확인하는 데 사용됩니다.","metadata":{}},{"id":"343acdc6-ff25-4a0d-bcbe-d94c83c30325","cell_type":"code","source":"DATA_YAML_PATH = \"/kaggle/input/pothole-detection-challenge/data.yaml\"\n\nwith open(DATA_YAML_PATH, \"r\", encoding=\"utf-8\") as f:\n    data_yaml = yaml.safe_load(f)\n\nDATASET_PATH = os.path.dirname(DATA_YAML_PATH)\nTRAIN_IMAGES = os.path.join(DATASET_PATH, data_yaml[\"train\"].replace(\"../\", \"\"))\nVALID_IMAGES = os.path.join(DATASET_PATH, data_yaml[\"val\"].replace(\"../\", \"\"))\n\nprint(DATASET_PATH)\nprint(TRAIN_IMAGES)\nprint(VALID_IMAGES)","metadata":{},"outputs":[],"execution_count":null},{"id":"4816e926-18d6-43ff-b5ac-59ef099d4037","cell_type":"markdown","source":"## 4. 데이터셋 클래스 정의 및 로드  \n객체 탐지 모델을 위한 이미지 데이터셋을 생성하고 불러오는 과정입니다.  \nOpenCV와 glob을 활용하여 이미지를 로드하고, torchvision.transforms를 적용해  \n크기 변환 및 텐서 변환을 수행합니다.  \n마지막으로 샘플 이미지를 시각화하여 데이터가 올바르게 불러와졌는지 확인합니다.","metadata":{}},{"id":"b8a4cb5a-eec4-497d-be3f-83bf1eae610c","cell_type":"code","source":"class PotholeDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_paths = glob(os.path.join(image_dir, \"*.jpg\"))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.image_paths[idx])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        return self.transform(img) if self.transform else img\n\n\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((640, 640)),\n    transforms.ToTensor(),\n])\n\ntrain_loader = DataLoader(PotholeDataset(TRAIN_IMAGES, transform), batch_size=16, shuffle=True)\nvalid_loader = DataLoader(PotholeDataset(VALID_IMAGES, transform), batch_size=16, shuffle=False)\n\n\ndef show_sample_images(image_loader):\n    sample_images = next(iter(image_loader))\n\n    fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n\n    for i, img in enumerate(sample_images[:6]):\n        ax[i // 3, i % 3].imshow(img.permute(1, 2, 0).numpy())\n        ax[i // 3, i % 3].axis(\"off\")\n\n    plt.show()\n\n\nprint(\"훈련 데이터 샘플\")\nshow_sample_images(train_loader)","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"id":"ad9cf97e","cell_type":"markdown","source":"## 5. 랜덤 샘플 시각화 (이미지 + 라벨)\n\n학습 이미지 중 하나를 랜덤으로 선택하여 해당 이미지와 라벨 정보를 시각화합니다.  \n라벨은 YOLO 포맷의 좌표 정보를 바탕으로 이미지 위에 바운딩 박스를 그려 확인합니다.\n","metadata":{}},{"id":"fca40583","cell_type":"code","source":"IMAGE_DIR = \"/kaggle/input/pothole-detection-challenge/train/images\"\nIMAGE_PATHS = sorted(glob(os.path.join(IMAGE_DIR, \"*.jpg\")))\n\nIMG_PATH = random.choice(IMAGE_PATHS)\nLABEL_PATH = IMG_PATH.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n\nimg = cv2.imread(IMG_PATH)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nh, w, _ = img.shape\n\nif os.path.exists(LABEL_PATH):\n    with open(LABEL_PATH, \"r\") as f:\n        for line in f.readlines():\n            cls, cx, cy, bw, bh = map(float, line.strip().split())\n            x1 = int((cx - bw / 2) * w)\n            y1 = int((cy - bh / 2) * h)\n            x2 = int((cx + bw / 2) * w)\n            y2 = int((cy + bh / 2) * h)\n            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 5)\n            cv2.putText(img, f\"Class {int(cls)}\", (x1, y1 - 10),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1)\nelse:\n    print(\"라벨 파일이 존재하지 않습니다:\", LABEL_PATH)\n\n# 시각화\nplt.figure(figsize=(6, 6))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(os.path.basename(IMG_PATH))\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"f4704726-43ef-4435-b8ad-fb9ad168dfce","cell_type":"markdown","source":"## 6. YOLO 모델 학습  \nYOLO 모델을 불러와 학습을 수행하는 코드입니다.  \n데이터셋 경로를 지정하고, 에포크 수 및 배치 크기를 설정하여 학습을 진행합니다.\n- 기본적으로 YOLO 학습 결과는 `runs/detect/train` 디렉토리에 저장됩니다.  \n- 캐글 환경에서는 저장 경로를 직접 지정해야 합니다.\n- `project` 및 `name` 파라미터를 사용하여 원하는 경로에 저장할 수 있습니다.","metadata":{}},{"id":"10ad5916-b92e-43d8-863d-2d3ddfeb8572","cell_type":"code","source":"model = YOLO(\"yolov8s.pt\")\n\ndef train_model():\n    results = model.train(\n        data=DATA_YAML_PATH,\n        epochs=5,\n        imgsz=320,\n        batch=8,\n        workers=4,\n        device=\"0\",\n        project=\"/kaggle/working\",\n        name=\"pothole_yolov8_train\"\n    )\n    return results\n\nresults = train_model()","metadata":{},"outputs":[],"execution_count":null},{"id":"f7668279-eae3-4232-b95d-6a2e1cf31333","cell_type":"markdown","source":"## 7. 학습 결과 시각화\n\nYOLO 모델 학습 과정에서 저장된 손실 그래프(`results.png`)를 불러와 시각화하는 코드입니다.  \n`matplotlib`을 사용하여 이미지를 출력하고, 그래프 외 요소는 제거하여 깔끔하게 보여줍니다.\n\n- 기본적으로 학습 결과는 `runs/detect/train` 디렉토리에 저장됩니다.  \n- 캐글 환경에서는 저장된 경로를 명시적으로 지정해주어야 합니다.\n","metadata":{}},{"id":"87b6ff02-1505-4ded-93d3-2d4c9294f6b8","cell_type":"code","source":"TRAIN_RUN_DIR = \"/kaggle/working/pothole_yolov8_train\"\nloss_plot_path = f\"{TRAIN_RUN_DIR}/results.png\"\n\nimg = plt.imread(loss_plot_path)\nplt.figure(figsize=(10, 5))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(\"Training Loss Graph\")\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"83538f09-2bc5-429f-9b38-264d61fcef56","cell_type":"markdown","source":"## 8. 모델 성능 평가  \n학습된 YOLO 모델을 불러와 검증 데이터셋을 이용해 성능을 평가하는 코드입니다.  \n`val()` 함수를 사용하여 `mAP`, `Precision`, `Recall` 등의 성능 지표를 계산합니다.\n\n- 캐글 환경에서는 모델이 저장된 경로를 지정해줘야 합니다.\n","metadata":{}},{"id":"92d1c126-ab8d-4c6c-b53b-88dc07563bfe","cell_type":"code","source":"model = YOLO(\"/kaggle/working/pothole_yolov8_train/weights/best.pt\")\n\nval_results = model.val(data=DATA_YAML_PATH, split=\"val\")\n\nprint(\"검증 데이터 평가 결과:\")\nprint(f\"mAP50: {val_results.box.map50:.4f}\")\nprint(f\"mAP50-95: {val_results.box.map:.4f}\")\nprint(f\"Precision: {val_results.box.mp:.4f}\")\nprint(f\"Recall: {val_results.box.mr:.4f}\")","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"id":"d06265be","cell_type":"markdown","source":"## 9. 모델 추론 및 시각화\n학습된 YOLO 모델을 사용하여 테스트 데이터셋에서 임의의 이미지를 추론합니다.\n\n- 포트홀을 감지하지 못하면 아무것도 표시되지 않습니다.","metadata":{}},{"id":"67d222bb-00d5-4bec-b382-1382daf35541","cell_type":"code","source":"model = YOLO(\"/kaggle/working/pothole_yolov8_train/weights/best.pt\")\n\nTEST_IMAGE_DIR = \"/kaggle/input/pothole-detection-challenge/test/images\"\ntest_image_paths = sorted(glob(os.path.join(TEST_IMAGE_DIR, \"*.jpg\")))\ntest_img_path = random.choice(test_image_paths)\n\nresults = model.predict(source=test_img_path, conf=0.25, imgsz=640, save=False)\n\nresult_img = results[0].plot()\n\nplt.figure(figsize=(8, 6))\nplt.imshow(result_img)\nplt.axis(\"off\")\nplt.title(f\"Inference Result: {os.path.basename(test_img_path)}\")\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"5e4413d5","cell_type":"markdown","source":"## 10. 제출 파일 생성 (submission.csv)\n테스트 이미지에 대해 학습된 YOLO 모델을 사용하여 객체 탐지를 수행하고,  \n예측 결과를 제출 형식에 맞춰 `submission.csv` 파일로 저장합니다.\n\n- 한 이미지당 박스 하나만 제출하며, confidence가 가장 높은 박스를 사용합니다.\n- 객체를 감지하지 못한 경우, `ClassId`와 바운딩 박스 좌표는 모두 0으로 처리합니다.\n- 이미지가 손상되었거나 열리지 않는 경우에도 에러 없이 넘어가도록 예외 처리를 포함합니다.\n- Output 경로인 /kagggle/working/에 저장됩니다.","metadata":{}},{"id":"a65db780","cell_type":"code","source":"import pandas as pd\n\nmodel = YOLO(\"/kaggle/working/pothole_yolov8_train/weights/best.pt\")\n\nTEST_IMG_DIR = \"/kaggle/input/pothole-detection-challenge/test/images\"\ntest_image_paths = sorted(glob(os.path.join(TEST_IMG_DIR, \"*.jpg\")))\n\nsubmission_rows = []\n\nfor img_path in test_image_paths:\n    image_id = os.path.basename(img_path)\n\n    if cv2.imread(img_path) is None:\n        print(f\"이미지 로드 실패: {image_id}\")\n        submission_rows.append({\n            \"ImageId\": image_id,\n            \"ClassId\": 0,\n            \"X\": 0,\n            \"Y\": 0,\n            \"Width\": 0,\n            \"Height\": 0,\n        })\n        continue\n\n    results = model.predict(source=img_path, conf=0.25, imgsz=640, save=False)\n    result = results[0]\n\n    if len(result.boxes) > 0:\n        boxes = result.boxes\n        best_idx = boxes.conf.argmax().item()\n        cls_id = int(boxes.cls[best_idx].item())\n        cx, cy, w, h = boxes.xywhn[best_idx].tolist()\n\n        submission_rows.append({\n            \"ImageId\": image_id,\n            \"ClassId\": cls_id,\n            \"X\": round(cx, 6),\n            \"Y\": round(cy, 6),\n            \"Width\": round(w, 6),\n            \"Height\": round(h, 6),\n        })\n    else:\n        submission_rows.append({\n            \"ImageId\": image_id,\n            \"ClassId\": 0,\n            \"X\": 0,\n            \"Y\": 0,\n            \"Width\": 0,\n            \"Height\": 0,\n        })\n\nsubmission_df = pd.DataFrame(submission_rows, columns=[\"ImageId\", \"ClassId\", \"X\", \"Y\", \"Width\", \"Height\"])\nsubmission_path = \"/kaggle/working/submission.csv\"\nsubmission_df.to_csv(submission_path, index=False)\nprint(f\"제출 파일 저장 완료: {submission_path}\")","metadata":{},"outputs":[],"execution_count":null}]}